{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w8BVbSAM0k8_"
   },
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "import seaborn as sb\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "DJjRViukzYYC",
    "outputId": "7276a632-f108-4712-e123-7645332cf459"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "e1Ftua89na47",
    "outputId": "b8c041ed-d124-49b4-cb99-1eb19dfaf4cf"
   },
   "outputs": [],
   "source": [
    "!ls \"/content/drive/My Drive/Bug Report classification\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "colab_type": "code",
    "id": "DNi-MTbK2Ua7",
    "outputId": "a0c291e6-23d5-4a4a-b839-1c81933ead08"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Input/Bug report.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "colab_type": "code",
    "id": "9Kdvl8581IRC",
    "outputId": "06c5b354-eacb-4b66-a940-967c25fc155f"
   },
   "outputs": [],
   "source": [
    "data.loc[:,'Issue Type'] = \"bug\"\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 305
    },
    "colab_type": "code",
    "id": "iSmGEEnc2ISE",
    "outputId": "bd33e1a4-4c2e-4ef0-f99a-42a7148adf67"
   },
   "outputs": [],
   "source": [
    "cols_of_interest=[\"Summary\", \"Description\", \"Issue Type\"]\n",
    "dataset=data[cols_of_interest]\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "id": "UCjjrShc-AJh",
    "outputId": "24f27fc9-1c47-42ff-ee77-3dad092359c7"
   },
   "outputs": [],
   "source": [
    "# Removing contents of tags and all for further text processing\n",
    "dataset['Description'].replace(regex=True,inplace=True, to_replace= r'<.+?>', value=r' ')\n",
    "dataset['Summary'].replace(regex=True,inplace=True, to_replace= r'<.+?>', value=r' ')\n",
    "\n",
    "# Removing links from all for further text processing\n",
    "dataset['Description'].replace(regex=True,inplace=True, to_replace= r'(https?:\\/\\/)(\\s)*(www\\.)?(\\s)*((\\w|\\s)+\\.)*([\\w\\-\\s]+\\/)*([\\w\\-]+)((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)*', value=r' ')\n",
    "dataset['Summary'].replace(regex=True,inplace=True, to_replace= r'(https?:\\/\\/)(\\s)*(www\\.)?(\\s)*((\\w|\\s)+\\.)*([\\w\\-\\s]+\\/)*([\\w\\-]+)((\\?)?[\\w\\s]*=\\s*[\\w\\%&]*)*', value=r' ')\n",
    "\n",
    "# Replace email addresses\n",
    "dataset['Description'].replace(regex=True,inplace=True, to_replace= r'^.+@[^\\.].*\\.[a-z]{2,}$', value=r'')\n",
    "dataset['Summary'].replace(regex=True,inplace=True, to_replace= r'^.+@[^\\.].*\\.[a-z]{2,}$', value=r'')\n",
    "\n",
    "# Replace URLs with 'web-address'\n",
    "dataset['Description'].replace(regex=True,inplace=True, to_replace= r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$', value=r'')\n",
    "dataset['Summary'].replace(regex=True,inplace=True, to_replace= r'^http\\://[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(/\\S*)?$', value=r'')\n",
    "\n",
    "# Replace 10 digit phone numbers\n",
    "dataset['Description'].replace(regex=True,inplace=True, to_replace= r'\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', value=r'')\n",
    "dataset['Summary'].replace(regex=True,inplace=True, to_replace= r'\\(?[\\d]{3}\\)?[\\s-]?[\\d]{3}[\\s-]?[\\d]{4}$', value=r'')\n",
    "\n",
    "# Replace numbers with 'numbr'\n",
    "dataset['Description'].replace(regex=True,inplace=True, to_replace= r'\\d+(\\.\\d+)?', value=r'')\n",
    "dataset['Summary'].replace(regex=True,inplace=True, to_replace= r'\\d+(\\.\\d+)?', value=r'')\n",
    "\n",
    "# Remove punctuation\n",
    "dataset['Description'].replace(regex=True,inplace=True, to_replace= r'[^\\w\\d\\s]', value=r'')\n",
    "dataset['Summary'].replace(regex=True,inplace=True, to_replace= r'[^\\w\\d\\s]', value=r'')\n",
    "\n",
    "#converting to lower case\n",
    "dataset['Description'] = dataset['Description'].str.lower()\n",
    "dataset['Summary'] = dataset['Summary'].str.lower()\n",
    "\n",
    "# Removing non-english content\n",
    "# dataset.drop(dataset[dataset.language!=\"english\"].index,inplace=True)\n",
    "\n",
    "# Removing rows with empty columns \n",
    "dataset.dropna(subset=['Description','Summary'],inplace=True)\n",
    "dataset.reset_index(inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "42yOwaqK8RzG",
    "outputId": "a8d9a05b-99c6-445b-ce7d-31fbc597f6e2"
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "i9akjFK8K3zr",
    "outputId": "76bf12d4-5de5-4ebf-9107-0d2e3ccfa704"
   },
   "outputs": [],
   "source": [
    "dataset['Issue Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "colab_type": "code",
    "id": "pA-ohsJM7lsl",
    "outputId": "47c6ab2c-2c78-4629-facc-a6e2e45b92af"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "dataset.groupby('Issue Type').Status.count().plot.bar(ylim=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DaL7nAR2DV2h"
   },
   "outputs": [],
   "source": [
    "final_c=['Bug','Improvement','New Feature','Sub-task','Task','Test','Wish']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 410
    },
    "colab_type": "code",
    "id": "xXyPQoP09tzT",
    "outputId": "f12975cf-65b9-4fe9-8faa-a10d19a4ed33"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label = LabelEncoder()\n",
    "dataset[\"Issue Type\"] = label.fit_transform(dataset[\"Issue Type\"])\n",
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "id": "V967ssT-oJet",
    "outputId": "c054a9d5-c9a2-4d95-d80a-6d7fe075a757"
   },
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YDePR3mGUFAq"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english',ngram_range=(1,2))\n",
    "vectorizer = tfidf.fit(dataset.Summary)\n",
    "transformed_summary = vectorizer.transform(dataset.Summary)\n",
    "#transformed_title = vectorizer.transform(dataset.Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "I-4-mHKgNWQr",
    "outputId": "fe410293-53fb-4446-d1c4-80349c98e430"
   },
   "outputs": [],
   "source": [
    "dataset[\"Created\"][26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A928VeuQXvdK"
   },
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Oao2Ifh5Us1P"
   },
   "outputs": [],
   "source": [
    "#Returns dictionary with term names and total tfidf scores for all terms in corpus\n",
    "def get_tfidf_term_scores(feature_names):\n",
    "    term_corpus_dict = {} \n",
    "    for term_ind, term in enumerate(feature_names):\n",
    "        term_name = feature_names[term_ind]\n",
    "        term_corpus_dict[term_name] = np.sum(transformed_summary.T[term_ind].toarray())\n",
    "        \n",
    "    return term_corpus_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P7C8yMF1W9we"
   },
   "outputs": [],
   "source": [
    "term_corpus_dict = get_tfidf_term_scores(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "40jS902yXCYc"
   },
   "outputs": [],
   "source": [
    "#Returns sort words from highest score to lowest score\n",
    "def get_sorted_tfidf_scores(term_corpus_dict):\n",
    "    sortedIndices = np.argsort( list(term_corpus_dict.values()))[::-1]\n",
    "    termNames = np.array(list(term_corpus_dict.keys()))\n",
    "    scores = np.array(list(term_corpus_dict.values()))\n",
    "    termNames = termNames[sortedIndices]\n",
    "    scores = scores[sortedIndices]\n",
    "    \n",
    "    return termNames, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JKepJ8NFaP-G"
   },
   "outputs": [],
   "source": [
    "termNames, scores = get_sorted_tfidf_scores(term_corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HaHhhlFcYqFT"
   },
   "outputs": [],
   "source": [
    "def plot_tfidf_scores(scores,termNames, n_words = 20):\n",
    "    '''Returns one plot for Importance of Top N Terms\n",
    "       and one plot for Importance of Select K Terms'''\n",
    "\n",
    "    # Create a figure instance, and the two subplots\n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "    \n",
    "    override = {'fontsize': 'large'}\n",
    "\n",
    "    fig.add_subplot(221)   \n",
    "    sb.set()\n",
    "    sb.barplot(x = scores[:n_words], y = termNames[:n_words]);\n",
    "    plt.title(\" Top tfidf score of top 20 words in Summary \".format(n_words));\n",
    "    plt.xlabel(\"TFIDF Score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 446
    },
    "colab_type": "code",
    "id": "Edftc_1nYs00",
    "outputId": "c53a7902-4e8d-4d7b-ac26-c3b5c1a7abb0"
   },
   "outputs": [],
   "source": [
    "plot_tfidf_scores(scores, termNames, n_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOJu0NlXfQmr"
   },
   "outputs": [],
   "source": [
    "diff_corpus=list()\n",
    "for i in range(0,7,1):\n",
    "  diff_corpus.append(list())\n",
    "for i in range(0,dataset.shape[0],1):\n",
    "  diff_corpus[dataset[\"Issue Type\"][i]].append(dataset.Summary[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1_QIS3hJihSB"
   },
   "outputs": [],
   "source": [
    "most_freq_w_in_class=list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "kPv0R4ZIc9XF",
    "outputId": "724d8ab5-95d7-4be8-c355-b9a64709ad7f"
   },
   "outputs": [],
   "source": [
    "for i in range(0,7,1):\n",
    "  vectorizer = tfidf.fit(diff_corpus[i])\n",
    "  transformed_summary = vectorizer.transform(diff_corpus[i])\n",
    "  feature_names = tfidf.get_feature_names()\n",
    "  term_corpus_dict = get_tfidf_term_scores(feature_names)\n",
    "  termNames, scores = get_sorted_tfidf_scores(term_corpus_dict)\n",
    "  most_freq_w_in_class.append(list(termNames[0:10]))\n",
    "  plot_tfidf_scores(scores, termNames, n_words = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FQYGLJaPg1i2"
   },
   "outputs": [],
   "source": [
    "#list(termNames[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CVRgY6SGhoY3",
    "outputId": "2f6ea0b0-571d-4275-b35f-9db1e7c846fd"
   },
   "outputs": [],
   "source": [
    "most_freq_w_in_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7Rzr1rXkd8j4",
    "outputId": "ed89e916-3946-4801-e176-f1f1bc56f731"
   },
   "outputs": [],
   "source": [
    "type(dataset.Summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "colab_type": "code",
    "id": "WYXYyqWNh2od",
    "outputId": "feaa9ab8-6340-425c-d4c7-8f840a5aa4d4"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fig = go.Figure(data=[go.Table(header=dict(values=['Bug','Improvement','New Feature','Sub-task','Task','Test','Wish']),\n",
    "                 cells=dict(values=most_freq_w_in_class))])\n",
    "fig.show()\n",
    "#fig.suptitle('test title', fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Jr3YJtFteqqt",
    "outputId": "5bc566fa-a030-4d75-8653-a9a0d99a77ec"
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "stop=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OCwnxgmka3BY"
   },
   "outputs": [],
   "source": [
    "l_of_words=list()\n",
    "for i in range(0,7,1):\n",
    "  l_of_words.append(list())\n",
    "for i in range(0,dataset.shape[0],1):\n",
    "  for w in dataset.Summary[i].split():\n",
    "    if w not in stop:\n",
    "      l_of_words[dataset[\"Issue Type\"][i]].append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "colab_type": "code",
    "id": "bDer1Zj7cKjS",
    "outputId": "65654c8b-c9e7-40de-b292-6a500b2fb923"
   },
   "outputs": [],
   "source": [
    "for i in range(0,7,1):\n",
    "  print(\"class \"+str(i))\n",
    "  print(l_of_words[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "OgmY_qavfR4F",
    "outputId": "b83bb732-95ec-4f52-d3be-d28c7526ebcd"
   },
   "outputs": [],
   "source": [
    "word_list=list()\n",
    "for i in range(0,7,1):\n",
    "  word_list.append(list())\n",
    "from collections import Counter \n",
    "for i in range(0,7,1):\n",
    "  Counte = Counter(l_of_words[i]) \n",
    "  most_occur = Counte.most_common(10) \n",
    "  for ele in most_occur:\n",
    "    word_list[i].append(ele[0])\n",
    "  print(most_occur) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "colab_type": "code",
    "id": "-aG8wkrZGjpy",
    "outputId": "a8864b6d-e409-45f6-88bd-66aaa2980257"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[go.Table(header=dict(values=['Bug','Improvement','New Feature','Sub-task','Task','Test','Wish']),\n",
    "                 cells=dict(values=word_list))\n",
    "                     ])\n",
    "fig.show()\n",
    "print(\"Top 10 Most Frequent Words In Each Category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b2DMvoC-Pkq6"
   },
   "outputs": [],
   "source": [
    "def difference_in_date(create,resolve):\n",
    "     vari=int(resolve[7:9])-int(create[7:9])\n",
    "     vari=vari*8760\n",
    "   \n",
    "    \n",
    "     dict={'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12}\n",
    "     if(dict[resolve[3:6]]>=dict[create[3:6]]):\n",
    "      vari+=(int(dict[resolve[3:6]])-int(dict[create[3:6]]))*720\n",
    "     else:\n",
    "      vari-=(int(dict[create[3:6]])-int(dict[resolve[3:6]]))*720\n",
    " \n",
    "    \n",
    "     if(int(create[0:2])<=int(resolve[0:2])):\n",
    "      vari+=(int(resolve[0:2])-int(create[0:2]))*24\n",
    "     else:\n",
    "      vari-=(int(create[0:2])-int(resolve[0:2]))*24\n",
    "     \n",
    "    \n",
    "     if(int(create[10:12])<=int(resolve[10:12])):\n",
    "      vari+=int(resolve[10:12])-int(create[10:12])\n",
    "     else:\n",
    "      vari-=int(create[10:12])-int(resolve[10:12])\n",
    "     \n",
    "    \n",
    "     if(int(create[13:15])<=int(resolve[13:15])):\n",
    "      vari+=(int(resolve[13:15])-int(create[13:15]))/60\n",
    "     else:\n",
    "      vari-=(int(create[13:15])-int(resolve[13:15]))/60\n",
    "     return vari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uuEnU1HC-lQa",
    "outputId": "d884e25c-4923-4ca5-c274-6571741b1892"
   },
   "outputs": [],
   "source": [
    "dataset.Created[3654],dataset.Resolved[3654]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2CfgsObkVxhW",
    "outputId": "7ec2b628-694d-438e-dd62-de7528c6c07b"
   },
   "outputs": [],
   "source": [
    "dict={'Jan':1,'Feb':2,'Mar':3,'Apr':4,'May':5,'Jun':6,'Jul':7,'Aug':8,'Sep':9,'Oct':10,'Nov':11,'Dec':12}\n",
    "dict[dataset.Created[1][3:6]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yqnWKlsRBqkA"
   },
   "outputs": [],
   "source": [
    "x=[0,0,0,0,0,0,0]\n",
    "y=[0,0,0,0,0,0,0]\n",
    "for i in range(0,dataset.shape[0],1):\n",
    "  z=difference_in_date(dataset.Created[i],dataset.Resolved[i])\n",
    "  x[dataset[\"Issue Type\"][i]]+=z\n",
    "  #if(z<0):\n",
    "   # print(i)\n",
    "  y[dataset[\"Issue Type\"][i]]+=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "bcmM3IY_PLQO",
    "outputId": "74fb8b76-3988-47c4-b655-6f0eb6c1aa0e"
   },
   "outputs": [],
   "source": [
    "final_mttr=[0,0,0,0,0,0,0]\n",
    "for i in range(0,7,1):\n",
    "  final_mttr[i]=x[i]/y[i]\n",
    "final_mttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "colab_type": "code",
    "id": "0ClGcHzZA0cO",
    "outputId": "dafda639-cd34-47de-d7b9-2761d26e3cbd"
   },
   "outputs": [],
   "source": [
    "\n",
    "   # this is for plotting mean time to repair\n",
    "    plt.figure(figsize=(8,6))\n",
    "    index = np.arange(len(final_c))\n",
    "    plt.bar(index,final_mttr)\n",
    "    plt.xlabel('Issue Type', fontsize=15)\n",
    "    plt.ylabel('MTTR (in hours)', fontsize=15)\n",
    "    plt.xticks(index, final_c, fontsize=15, rotation=80)\n",
    "    plt.title('Mean Time To Repair for Each Issue Type')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "oyUMwvQEPu6B",
    "outputId": "03e52afe-ece0-414c-dd47-e7dcdc4d1162"
   },
   "outputs": [],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PltnjngWPy33"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "dataset.to_csv('final1.csv')\n",
    "#files.download('final1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 546
    },
    "colab_type": "code",
    "id": "R8syhBPlQFbP",
    "outputId": "36dfe219-7e16-4b48-9d60-43564ed35e8a"
   },
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "V2BV18Xug91r",
    "outputId": "f3a65735-4f43-42c5-ee3f-4fd329117ae4"
   },
   "outputs": [],
   "source": [
    "print(\"The data-set has %d rows and %d columns\"%(dataset.shape[0],dataset.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EbuuEfWTjArM"
   },
   "source": [
    "# Finding out which columns has the missing values not needed although since we would be working with either summary or description and usme koi missing values nhi hai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "MW1H2F3RiZqk",
    "outputId": "e5fea4ac-d78f-4496-d06b-e66e64df3250"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "print (dataset.columns)\n",
    "for col_name in dataset.columns:\n",
    "    print (col_name,end=\": \")\n",
    "    print (sum(dataset[col_name].isnull()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9WtfxdlBkEA2"
   },
   "source": [
    "# To see which rows are duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "MQSEb5-Yir1h",
    "outputId": "2307df66-5f04-4883-c8ff-a5b7d03c925d"
   },
   "outputs": [],
   "source": [
    "sum(dataset.duplicated()) # which is indeed very good as the result is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tra0mi57nE1Y"
   },
   "source": [
    "# finding out class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DJj10ESnjNkw"
   },
   "outputs": [],
   "source": [
    "category_counter={x:0 for x in set(dataset['Issue Type'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "njtYI255nIwS"
   },
   "outputs": [],
   "source": [
    "for each_cat in dataset['Issue Type']:\n",
    "    category_counter[each_cat]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w-93Ae4CnT0E",
    "outputId": "677eb8b3-3ec4-44b9-cb68-c7fbb196e1ce"
   },
   "outputs": [],
   "source": [
    "print(category_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "27CG9-e6qy3a"
   },
   "source": [
    "#Combining the Columns of summary and description and then applying NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "WXkf0r8xncQZ",
    "outputId": "503d0f6a-ae3d-4078-b3eb-5b78ad930381"
   },
   "outputs": [],
   "source": [
    "dataset['Description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "colab_type": "code",
    "id": "7U01aNIvrHVN",
    "outputId": "caaadd2f-a6a8-4fe5-cffd-cca1eac4893e"
   },
   "outputs": [],
   "source": [
    "dataset['Summary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 115
    },
    "colab_type": "code",
    "id": "clhyG0tZq_Jt",
    "outputId": "7eb35ddd-0122-4d3b-a00b-7118e325a0b9"
   },
   "outputs": [],
   "source": [
    "dataset[\"Merger\"] = dataset[\"Summary\"].str.cat(dataset[\"Description\"], sep =\" \\n \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "id": "2Vq1G-dfrkk_",
    "outputId": "c9eda655-c1e8-46e0-8389-d793cce54afd"
   },
   "outputs": [],
   "source": [
    "dataset['Merger']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "colab_type": "code",
    "id": "aENI8EwDsF8O",
    "outputId": "56213b66-802f-4793-fc22-156342636a3d"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_WRKA0KrfWoT"
   },
   "outputs": [],
   "source": [
    "corpus=dataset.Merger\n",
    "#corpus means collection of text. For this particular data-set, I will treat the newly created column merger\n",
    "#as my corpus and will use that to create features.\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "#Initializing TFIDF vectorizer to conver the raw corpus to a matrix of TFIDF features and also enabling the removal of stopwords.\n",
    "tfidf_matrix=vectorizer.fit_transform(corpus).todense()\n",
    "#creating TFIDF features sparse matrix by fitting it on the specified corpus. \n",
    "tfidf_names=vectorizer.get_feature_names()\n",
    "#grabbing the name of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "arGLbaeAhPto",
    "outputId": "1c8374b3-f61f-4742-ff22-12cbde3ffbb7"
   },
   "outputs": [],
   "source": [
    "print(\"Number of TFIDF Features: %d\"%len(tfidf_names)) #same info can be gathered by using tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FxhvulcRxJ1B"
   },
   "outputs": [],
   "source": [
    "training_time_container={'b_naive_bayes':0,'mn_naive_bayes':0,'random_forest':0,'linear_svm':0}\n",
    "prediction_time_container={'b_naive_bayes':0,'mn_naive_bayes':0,'random_forest':0,'linear_svm':0}\n",
    "\n",
    "accuracy_container={'b_naive_bayes':0,'mn_naive_bayes':0,'random_forest':0,'linear_svm':0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oig_AgllhdY9"
   },
   "source": [
    "#**Learning Classifiers, Making Predictions and Validating Results**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WumPPuCfYsbc"
   },
   "source": [
    "##**Set the GPU to on before training for lesser training time.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KTl1_sW3xqGy"
   },
   "outputs": [],
   "source": [
    "dataset.columns=[\"index\",\"Issue_key\",\"Issue_id\",\"Summary\",\"Status\",\"Description\",\"Priority\",\"Resolution\",\"Assignee\",\"Created\",\"Updated\",\"Last_Viewed\",\"Resolved\",\"Issue_Type\",\"Merger\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-5LCExKcjsc0"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "colab_type": "code",
    "id": "YoOCEffRkRha",
    "outputId": "6bcbe86d-5e49-4099-d66a-99db4b271c21"
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1WuGMscxhXSo"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    "variables = tfidf_matrix\n",
    "labels = dataset.Issue_Type\n",
    "variables_train, variables_test, labels_train, labels_test = train_test_split(variables, labels, test_size=.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "NInQ-x2eiOLL",
    "outputId": "d89b85b3-2562-430d-fdb7-6616813249e2"
   },
   "outputs": [],
   "source": [
    "#analyzing the shape of the training and test data-set:\n",
    "print('Shape of Training Data: '+str(variables_train.shape))\n",
    "print('Shape of Test Data: '+str(variables_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLepCuTZyoV0"
   },
   "source": [
    "#**Applying Naive Bayes**\n",
    "\n",
    "two types:-\n",
    "*   Bernoulli\n",
    "*   Multinomial\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "WBYAoCm3yO4Z",
    "outputId": "fbb50b49-c21a-4414-da80-565ba03a4b5d"
   },
   "outputs": [],
   "source": [
    "training_time_container.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "si22km0Rz-Js"
   },
   "source": [
    "#**Bernoulli**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dE3xHrMay6sn"
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "#loading Gaussian Naive Bayes from the sklearn library:\n",
    "bnb_classifier=BernoulliNB()\n",
    "#initializing the object\n",
    "t0=time()\n",
    "bnb_classifier=bnb_classifier.fit(variables_train,labels_train)\n",
    "training_time_container['b_naive_bayes']=time()-t0\n",
    "#fitting the classifier or training the classifier on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qH6wroshzAlW"
   },
   "outputs": [],
   "source": [
    "#after the model has been trained, we proceed to test its performance on the test data:\n",
    "t0=time()\n",
    "bnb_predictions=bnb_classifier.predict(variables_test)\n",
    "prediction_time_container['b_naive_bayes']=time()-t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "RHPPaPnUzRKu",
    "outputId": "cb58ef4c-67b9-4a15-8dcb-05644cd0b70e"
   },
   "outputs": [],
   "source": [
    "prediction_time_container['b_naive_bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZUbl7-Z_zUym"
   },
   "outputs": [],
   "source": [
    "nb_ascore=sklearn.metrics.accuracy_score(labels_test, bnb_predictions)\n",
    "accuracy_container['b_naive_bayes']=nb_ascore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "6fOjfXg9zZyk",
    "outputId": "b3ddb46a-0d03-4902-ecae-534107fb9b10"
   },
   "outputs": [],
   "source": [
    "print(\"Bernoulli Naive Bayes Accuracy Score: %f\"%accuracy_container['b_naive_bayes'])\n",
    "print(\"Training Time: %f\"%training_time_container['b_naive_bayes'])\n",
    "print(\"Prediction Time: %f\"%prediction_time_container['b_naive_bayes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "colab_type": "code",
    "id": "4wlColc0zctA",
    "outputId": "9bc49e6a-2f4b-4726-ae5f-f42639065d56"
   },
   "outputs": [],
   "source": [
    "print(\"Confusion Matrix of Bernoulli Naive Bayes Classifier output: \")\n",
    "sklearn.metrics.confusion_matrix(labels_test,bnb_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "HgrgkO7IzkRo",
    "outputId": "8a050baa-6405-4562-a1fb-97e1e4d516f1"
   },
   "outputs": [],
   "source": [
    "print(\"Classification Metrics: \")\n",
    "print(sklearn.metrics.classification_report(labels_test,bnb_predictions))\n",
    "#accuracy score can be misleading when there is class imbalance problem in the data-set. \n",
    "# F1-Score is a better measure of a classifier performance. The greater the F1-Score, the better. Also, we can see\n",
    "#that F1-Score and Accuracy score are somewhat similar because the data-set has negligible class imbalance issue:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PUMP15VE2GrG"
   },
   "source": [
    "#**Multinomial Naive Bayes**\n",
    "Bernoulli Naive Bayes just uses the fact that whether a feature is present or not. However if we somehow also take into account the occurrence weight or count of the feature as well (in our case, the TFIDF weight of each feature), we can hypothesize that the performance of such classifier will be equally good, if not better. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MIanlL4qzwk8"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mn_bayes=MultinomialNB()\n",
    "t0=time()\n",
    "mn_bayes_fit=mn_bayes.fit(variables_train,labels_train)\n",
    "training_time_container['mn_naive_bayes']=time()-t0\n",
    "t0=time()\n",
    "prediction_mn=mn_bayes_fit.predict(variables_test)\n",
    "prediction_time_container['mn_naive_bayes']=time()-t0\n",
    "mn_ascore=sklearn.metrics.accuracy_score(labels_test, prediction_mn) \n",
    "accuracy_container['mn_naive_bayes']=mn_ascore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66
    },
    "colab_type": "code",
    "id": "R2abkcke2aoy",
    "outputId": "e0b12694-0825-4f01-fee1-94b3d20b076f"
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy Score of Multi-Nomial Naive Bayes: %f\" %(mn_ascore))\n",
    "#and its training and prediction time are:\n",
    "print(\"Training Time: %fs\"%training_time_container['mn_naive_bayes'])\n",
    "print(\"Prediction Time: %fs\"%prediction_time_container['mn_naive_bayes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "osj5AdhA3cHQ"
   },
   "source": [
    "#**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "EF2TvWKo2e-X",
    "outputId": "df1f37be-33e3-4145-91c3-7b8ad6e6f0ae"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier=RandomForestClassifier(n_estimators=50)\n",
    "t0=time()\n",
    "rf_classifier=rf_classifier.fit(variables_train,labels_train)\n",
    "\n",
    "training_time_container['random_forest']=time()-t0\n",
    "print(\"Training Time: %fs\"%training_time_container['random_forest'])\n",
    "\n",
    "t0=time()\n",
    "rf_predictions=rf_classifier.predict(variables_test)\n",
    "prediction_time_container['random_forest']=time()-t0\n",
    "print(\"Prediction Time: %fs\"%prediction_time_container['random_forest'])\n",
    "\n",
    "accuracy_container['random_forest']=sklearn.metrics.accuracy_score(labels_test, rf_predictions)\n",
    "print (\"Accuracy Score of Random Forests Classifier: \")\n",
    "print(accuracy_container['random_forest'])\n",
    "print(sklearn.metrics.confusion_matrix(labels_test,rf_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JiZgPxWS39uK"
   },
   "source": [
    "#**Linear SVM using Stochastic Gradient Descent**\n",
    "Stochastic Gradient Descent (SGD) is a one of the most efficient approaches used in linear classifiers under convex loss functions such as (linear) Support Vector Machines. It has proven to perform well in in large-scale and sparse machine learning problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 180
    },
    "colab_type": "code",
    "id": "RMJIK5-i3kkY",
    "outputId": "10115a98-1898-4c30-caaa-2450cd1c6240"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "svm_classifier=linear_model.SGDClassifier(loss='hinge',alpha=0.0001)\n",
    "\n",
    "t0=time()\n",
    "svm_classifier=svm_classifier.fit(variables_train, labels_train)\n",
    "training_time_container['linear_svm']=time()-t0\n",
    "print(\"Training Time: %fs\"%training_time_container['linear_svm'])\n",
    "\n",
    "t0=time()\n",
    "svm_predictions=svm_classifier.predict(variables_test)\n",
    "prediction_time_container['linear_svm']=time()-t0\n",
    "print(\"Prediction Time: %fs\"%prediction_time_container['linear_svm'])\n",
    "\n",
    "accuracy_container['linear_svm']=sklearn.metrics.accuracy_score(labels_test, svm_predictions)\n",
    "print (\"Accuracy Score of Linear SVM Classifier: %f\"%accuracy_container['linear_svm'])\n",
    "print(sklearn.metrics.confusion_matrix(labels_test,svm_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "kS5iNdiy4TlK",
    "outputId": "663ff441-e8f7-4c08-a843-74b23dfe7e79"
   },
   "outputs": [],
   "source": [
    "#if we train the SGD Classifier with elastic net penalty, it  brings more sparsity to the model not possible with the L2:\n",
    "svm_classifier_enet=linear_model.SGDClassifier(loss='hinge',alpha=0.0001,penalty='elasticnet')\n",
    "svm_classifier_enet=svm_classifier_enet.fit(variables_train, labels_train)\n",
    "svm_enet_predictions=svm_classifier_enet.predict(variables_test)\n",
    "print (\"Accuracy Score of Linear SVM Classifier: %f\"%sklearn.metrics.accuracy_score(labels_test,svm_enet_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "id": "KtDzZbJ27GFK",
    "outputId": "06634fcb-0afe-4d0c-cca9-220c483af8fe"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.bar(range(4),training_time_container.values(),align='center')\n",
    "    plt.xticks(range(4),training_time_container.keys(),fontsize = 15)\n",
    "    plt.ylabel(\"Training time in seconds\")\n",
    "    plt.ylim(0,100)\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Comparison of Training Time of different classifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "id": "LSIiLJJjZU14",
    "outputId": "9c2753f0-ea73-4d2d-fa14-089fb8d37525"
   },
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.bar(range(4),prediction_time_container.values(),align='center',color='orange')\n",
    "    plt.xticks(range(4),prediction_time_container.keys(),fontsize = 15)\n",
    "    plt.ylabel(\"Prediction time in seconds\")\n",
    "    plt.grid(True)\n",
    "    plt.ylim(0,2)\n",
    "    plt.title(\"Comparison of Prediction Time of different classifiers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "colab_type": "code",
    "id": "bSkr-APxf7B8",
    "outputId": "c27ee581-6d10-41f4-8540-eb1530ad417f"
   },
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(20,8))\n",
    "    plt.bar(range(4),accuracy_container.values(),align='center',color='g')\n",
    "    plt.xticks(range(4),accuracy_container.keys(),fontsize = 15)\n",
    "    plt.ylabel(\"Accuracy Scores\")\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Comparison of Accuracy Scores of different classifiers\")\n",
    "    plt.ylim(0.5,1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LCJHhZgbg2pr"
   },
   "source": [
    "#**So far we are using the unbalanced dataset, thats why we get such less accuracy upon every classifier.**\n",
    "#**Suggestions to improve the accuracy and improving the readability are welcomed**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jBwqw9CBdf2F"
   },
   "source": [
    "#**Ensemble Learning**\n",
    "\n",
    "##Voting Classifier\n",
    "\n",
    "training_time_container={'b_naive_bayes':0,'mn_naive_bayes':0,'random_forest':0,'linear_svm':0}\n",
    "\n",
    "prediction_time_container={'b_naive_bayes':0,'mn_naive_bayes':0,'random_forest':0,'linear_svm':0}\n",
    "\n",
    "accuracy_container={'b_naive_bayes':0,'mn_naive_bayes':0,'random_forest':0,'linear_svm':0}\n",
    "\n",
    "#Variables used earlier for classifiers.\n",
    "\n",
    "bnb_classifier=BernoulliNB()\n",
    "\n",
    "mn_bayes=MultinomialNB()\n",
    "\n",
    "rf_classifier=RandomForestClassifier(n_estimators=50)\n",
    "\n",
    "svm_classifier=linear_model.SGDClassifier(loss='hinge',alpha=0.0001)\n",
    "\n",
    "nl_svm_classifier=SVC(C=1000000.0, gamma='auto_deprecated', kernel='rbf')\n",
    "\n",
    "variables_train, variables_test, labels_train, labels_test  =   train_test_split(variables, labels, test_size=.3)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Jo92VFy_z8rp"
   },
   "source": [
    "#**Hard Voting / Majority Voting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Bi8KZ8Z9gpxy"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "estimators = []\n",
    "estimators.append(('Bernoulli',bnb_classifier))\n",
    "estimators.append(('Multinomial',mn_bayes))\n",
    "estimators.append(('RandomForest',rf_classifier))\n",
    "estimators.append(('SVMLinear',svm_classifier))\n",
    "#estimators.append(('SVMNonLinear',nl_svm_classifier))\n",
    "ensemble = VotingClassifier(estimators,voting = 'hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "X3KQfoO4ihaW",
    "outputId": "c3322e64-82d0-4d17-e252-9e2be402ecda"
   },
   "outputs": [],
   "source": [
    "#fit model to training data\n",
    "t0=time()\n",
    "ensemble.fit(variables_train, labels_train)\n",
    "\n",
    "ensemble_training_time=time()-t0\n",
    "training_time_container['Hard'] = ensemble_training_time\n",
    "print(\"Training Time: %fs\"%ensemble_training_time)\n",
    "#test our model on the test data\n",
    "ensemble.score(variables_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "_Q7Bb5sxX98-",
    "outputId": "b08c4784-b2f5-4de7-fad9-01f9cb34cd0b"
   },
   "outputs": [],
   "source": [
    "t0=time()\n",
    "ensemble_predictions=ensemble.predict(variables_test)\n",
    "ensemble_prediction_time = time() - t0\n",
    "prediction_time_container['Hard'] = ensemble_prediction_time\n",
    "print(\"Prediction Time: %fs\"%ensemble_prediction_time)\n",
    "\n",
    "accuracy_container['Ensemble_hard']=sklearn.metrics.accuracy_score(labels_test, ensemble_predictions)\n",
    "print(\"Accuracy Score of Hard-Voting Ensemble is : %f\" %accuracy_container['Ensemble_hard'])\n",
    "\n",
    "print(sklearn.metrics.confusion_matrix(labels_test,ensemble_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nz5Mz7K21lTL"
   },
   "source": [
    "##If ‘soft’, predicts the class label based on the argmax of the sums of the predicted probabilities, which is recommended for an ensemble of well-calibrated classifiers.\n",
    "\n",
    "So what we need is calibrated classifiers Svm me loss= hinge rahega to classifier is non calibrated first calibrate it.\n",
    "\n",
    "\n",
    "SGDClassifier(loss = 'hinge') does not have probability by default.\n",
    "\n",
    "You have to pass SGDclassifier(loss = 'hinge') to CalibratedClassifierCV() which will calculate the probability values of SGDclassifier(loss = 'hinge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BtbBUsAx2n53"
   },
   "outputs": [],
   "source": [
    "svm_classifier=svm_classifier.fit(variables_train, labels_train)\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "svm_calibrator = CalibratedClassifierCV(svm_classifier, cv='prefit')\n",
    "svm_calibrator = svm_calibrator.fit(variables_train, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "QfwutPGeryFC",
    "outputId": "7477cf75-517d-470c-8be6-423269f4fd2e"
   },
   "outputs": [],
   "source": [
    "estimators1 = []\n",
    "estimators1.append(('Bernoulli',bnb_classifier))\n",
    "estimators1.append(('Multinomial',mn_bayes))\n",
    "estimators1.append(('RandomForest',rf_classifier))\n",
    "ensemble2 = VotingClassifier(estimators1,voting = 'soft')\n",
    "#fit model to training data\n",
    "t0=time()\n",
    "ensemble2.fit(variables_train, labels_train)\n",
    "\n",
    "ensemble2_training_time=time()-t0\n",
    "print(\"Training Time: %fs\"%ensemble2_training_time)\n",
    "#test our model on the test data\n",
    "print(\"Accuracy: %fs\"%ensemble2.score(variables_test, labels_test))\n",
    "t0=time()\n",
    "ensemble2_predictions=ensemble2.predict(variables_test)\n",
    "ensemble2_prediction_time = time() - t0\n",
    "training_time_container['soft'] = ensemble2_training_time\n",
    "prediction_time_container['soft'] = ensemble2_prediction_time\n",
    "print(\"Prediction Time: %fs\"%ensemble2_prediction_time)\n",
    "\n",
    "accuracy_container['Ensemble_soft']=sklearn.metrics.accuracy_score(labels_test, ensemble2_predictions)\n",
    "print(\"Accuracy Score of Soft-Voting Ensemble is : %f\" %accuracy_container['Ensemble_soft'])\n",
    "\n",
    "print(sklearn.metrics.confusion_matrix(labels_test,ensemble2_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T5JOMpA_6qma"
   },
   "source": [
    "#**Bagged Decision Trees**\n",
    "## BaggingClassifier with the Classification and Regression Trees algorithm (DecisionTreeClassifier). A total of 100 trees are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "qH-abJPgz20T",
    "outputId": "a5996a7f-9668-4786-e2c3-4f794dfbeeef"
   },
   "outputs": [],
   "source": [
    "from time import time \n",
    "import random\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "cart = DecisionTreeClassifier()\n",
    "num_trees = 100       #tweaking this value for accuracy increase, but keep an eye for overfitting.\n",
    "Bagging_classifier= BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=random.seed())\n",
    "t0=time()\n",
    "Bagging_classifier.fit(variables_train, labels_train)\n",
    "\n",
    "BaggingClassifier_training_time=time()-t0\n",
    "print(\"Training Time: %fs\"%BaggingClassifier_training_time)\n",
    "training_time_container['bagging'] = BaggingClassifier_training_time\n",
    "\n",
    "#test our model on the test data\n",
    "print(\"Accuracy: %fs\"%Bagging_classifier.score(variables_test, labels_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "id": "n5dRiwmrxSvi",
    "outputId": "147f8d20-9b8a-4b80-89bd-93d389d7a41b"
   },
   "outputs": [],
   "source": [
    "t0=time()\n",
    "BaggingClassifier_predictions=Bagging_classifier.predict(variables_test)\n",
    "BaggingClassifier_prediction_time = time() - t0\n",
    "print(\"Prediction Time: %fs\"%BaggingClassifier_prediction_time)\n",
    "prediction_time_container['bagging'] = BaggingClassifier_prediction_time\n",
    "\n",
    "accuracy_container['Bagging_classifier']=sklearn.metrics.accuracy_score(labels_test, BaggingClassifier_predictions)\n",
    "print(\"Accuracy Score of Bagging classifier is : %f\" %accuracy_container['Bagging_classifier'])\n",
    "\n",
    "print(sklearn.metrics.confusion_matrix(labels_test,BaggingClassifier_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PEGSJD7oDoGN"
   },
   "source": [
    "#**Boosting Algorithm**\n",
    "##**Adaboost**\n",
    "\n",
    "It generally works by weighting instances in the dataset by how easy or difficult they are to classify, allowing the algorithm to pay or or less attention to them in the construction of subsequent models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 196
    },
    "colab_type": "code",
    "id": "EHHGnq_Q8c5Y",
    "outputId": "5fc7cfec-3717-4ff9-cfff-b873da7045a0"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "seed = 7\n",
    "num_trees = 100\n",
    "Adaboost_classifier = AdaBoostClassifier(n_estimators=num_trees, random_state=seed)\n",
    "t0=time()\n",
    "Adaboost_classifier.fit(variables_train, labels_train)\n",
    "\n",
    "AdaboostClassifier_training_time=time()-t0\n",
    "print(\"Training Time: %fs\"%AdaboostClassifier_training_time)\n",
    "\n",
    "#test our model on the test data\n",
    "print(\"Accuracy: %fs\"%Adaboost_classifier.score(variables_test, labels_test))\n",
    "t0=time()\n",
    "AdaboostClassifier_predictions = Adaboost_classifier.predict(variables_test)\n",
    "AdaboostClassifier_prediction_time = time() - t0\n",
    "print(\"Prediction Time: %fs\"%AdaboostClassifier_prediction_time)\n",
    "training_time_container['adaboost'] = AdaboostClassifier_training_time\n",
    "prediction_time_container['adaboost'] = AdaboostClassifier_prediction_time\n",
    "\n",
    "accuracy_container['Adaboost_classifier']=sklearn.metrics.accuracy_score(labels_test, AdaboostClassifier_predictions)\n",
    "print(\"Accuracy Score of Adaboost classifier is : %f\" %accuracy_container['Adaboost_classifier'])\n",
    "\n",
    "print(sklearn.metrics.confusion_matrix(labels_test,AdaboostClassifier_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "25g6dJEh1BtI"
   },
   "source": [
    "##**Stochastic Gradient Boosting**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "id": "t7uKu5yJ0-7e",
    "outputId": "314c2ba2-60f6-4236-ab6e-78a27d8354c1"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "seed = 7\n",
    "num_trees = 100\n",
    "SGB_classifier = GradientBoostingClassifier(n_estimators=num_trees, random_state=seed)\n",
    "t0=time()\n",
    "SGB_classifier.fit(variables_train, labels_train)\n",
    "\n",
    "SGBClassifier_training_time=time()-t0\n",
    "print(\"Training Time: %fs\"%SGBClassifier_training_time)\n",
    "\n",
    "#test our model on the test data\n",
    "print(\"Accuracy: %fs\"%SGB_classifier.score(variables_test, labels_test))\n",
    "t0=time()\n",
    "SGBClassifier_predictions = SGB_classifier.predict(variables_test)\n",
    "SGBClassifier_prediction_time = time() - t0\n",
    "print(\"Prediction Time: %fs\"%SGBClassifier_prediction_time)\n",
    "training_time_container['sgb'] = SGBClassifier_training_time\n",
    "prediction_time_container['sgb'] = SGBClassifier_prediction_time\n",
    "\n",
    "accuracy_container['SGB_classifier']=sklearn.metrics.accuracy_score(labels_test, SGBClassifier_predictions)\n",
    "print(\"Accuracy Score of SGB_classifier is : %f\" %accuracy_container['SGB_classifier'])\n",
    "\n",
    "print(sklearn.metrics.confusion_matrix(labels_test,SGBClassifier_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fNkAwpg86JmN"
   },
   "source": [
    "## so what we get is useless accuracy beacuse the dataset is actually highly unbalanced and would not show any good result.\n",
    "Two things for future work, Cross validation or correcting our dataset ie doing a class balance for the dataset.\n",
    "\n",
    "not much hope attached to cross validation. Class balance by creating copy class wise seems to be the only option for now.\n",
    "\n",
    "moreover what's astounding is that the individual classifiers are performing way better than ensemble, although the reverse should have happened."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pVK1btJH4-ky"
   },
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(25,8))\n",
    "    plt.bar(range(9),accuracy_container.values(),align='center',color='g')\n",
    "    plt.xticks(range(9),accuracy_container.keys(),fontsize = 15)\n",
    "    plt.ylabel(\"Accuracy Scores\")\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Comparison of Accuracy Scores of different classifiers\")\n",
    "    plt.ylim(0.3,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mb7t-JJ7RZ_s"
   },
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(25,8))\n",
    "    plt.bar(range(9),training_time_container.values(),align='center',color='g')\n",
    "    plt.xticks(range(9),training_time_container.keys(),fontsize = 15)\n",
    "    plt.ylabel(\"training time\")\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Comparison of training time of different classifiers\")\n",
    "    plt.ylim(0.3,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NbIAwidEVPKC"
   },
   "outputs": [],
   "source": [
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.figure(figsize=(25,8))\n",
    "    plt.bar(range(9),prediction_time_container.values(),align='center',color='g')\n",
    "    plt.xticks(range(9),prediction_time_container.keys(),fontsize = 15)\n",
    "    plt.ylabel(\"prediction time\")\n",
    "    plt.grid(True)\n",
    "    plt.title(\"Comparison of prediction time of different classifiers\")\n",
    "    plt.ylim(0.3,1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YeZfznFVxdoQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Somil's Copy of project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
